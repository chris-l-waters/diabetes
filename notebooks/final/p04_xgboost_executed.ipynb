{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3456248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:53.656952Z",
     "iopub.status.busy": "2025-07-07T15:27:53.656631Z",
     "iopub.status.idle": "2025-07-07T15:27:53.665209Z",
     "shell.execute_reply": "2025-07-07T15:27:53.664930Z"
    },
    "papermill": {
     "duration": 0.013103,
     "end_time": "2025-07-07T15:27:53.665892",
     "exception": false,
     "start_time": "2025-07-07T15:27:53.652789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Available memory before training: 6.10 GB\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "\n",
    "import psutil\n",
    "print(f\"Available memory before training: {psutil.virtual_memory().available / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4d15f",
   "metadata": {
    "papermill": {
     "duration": 0.001336,
     "end_time": "2025-07-07T15:27:53.668801",
     "exception": false,
     "start_time": "2025-07-07T15:27:53.667465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Diabetes Readmission – XGBoost Gradient Boosting\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook implements XGBoost (eXtreme Gradient Boosting) for predicting hospital readmission within 30 days for diabetic patients. We use the preprocessed dataset designed for tree-based methods, which includes:\n",
    "\n",
    "- Full dataset: All encounters retained (101,763 records), as tree-based methods can handle correlated observations\n",
    "- Binary and count features: ICD-9 diagnostic codes expanded into both indicator variables and count-based features\n",
    "- Categorical encoding: Ordinal encoding for categorical variables (optimal for tree-based models)\n",
    "- Raw numeric features: No scaling required as XGBoost is invariant to monotonic transformations\n",
    "\n",
    "## Methodology\n",
    "\n",
    "**No Class Imbalance Handling**: XGBoost naturally handles class imbalance through built-in mechanisms like `scale_pos_weight` parameter, eliminating the need for synthetic sampling techniques.\n",
    "\n",
    "**Gradient Boosting Approach**: XGBoost builds an ensemble of weak decision trees sequentially, where each tree corrects the errors of previous trees. Key advantages include:\n",
    "- Feature interaction detection: Automatically captures complex non-linear relationships\n",
    "- Missing value handling: Native support for missing data without imputation\n",
    "- Regularization: Built-in L1 and L2 regularization prevents overfitting\n",
    "\n",
    "**Hyperparameter Optimization**: Using Optuna's intelligent search across 9 key parameters:\n",
    "- Tree structure: `n_estimators`, `max_depth`, `min_child_weight`\n",
    "- Learning dynamics: `learning_rate`, `subsample`, `colsample_bytree`\n",
    "- Regularization: `reg_alpha`, `reg_lambda`\n",
    "- Class handling: `scale_pos_weight`\n",
    "\n",
    "**Preprocessing Pipeline**: Ordinal encoding for categorical features while preserving numeric features as-is, resulting in ~147 features optimized for tree-based learning.\n",
    "\n",
    "The goal is to leverage XGBoost's ability to capture complex feature interactions and non-linear patterns that linear models cannot detect, while maintaining robust performance through proper regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff6beca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:53.671723Z",
     "iopub.status.busy": "2025-07-07T15:27:53.671644Z",
     "iopub.status.idle": "2025-07-07T15:27:54.583076Z",
     "shell.execute_reply": "2025-07-07T15:27:54.582775Z"
    },
    "papermill": {
     "duration": 0.913787,
     "end_time": "2025-07-07T15:27:54.583833",
     "exception": false,
     "start_time": "2025-07-07T15:27:53.670046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649c322d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.587121Z",
     "iopub.status.busy": "2025-07-07T15:27:54.586998Z",
     "iopub.status.idle": "2025-07-07T15:27:54.678195Z",
     "shell.execute_reply": "2025-07-07T15:27:54.677929Z"
    },
    "papermill": {
     "duration": 0.093713,
     "end_time": "2025-07-07T15:27:54.679057",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.585344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = 'f11' # iteratable by the user as we try new things\n",
    "randy = 42 # random value insertion for repeatability\n",
    "random_forests = pd.read_pickle(\"../models/randomForests.pkl\") # See prior notebook, p02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423cd1d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.683075Z",
     "iopub.status.busy": "2025-07-07T15:27:54.682948Z",
     "iopub.status.idle": "2025-07-07T15:27:54.687474Z",
     "shell.execute_reply": "2025-07-07T15:27:54.687288Z"
    },
    "papermill": {
     "duration": 0.007361,
     "end_time": "2025-07-07T15:27:54.688065",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.680704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 101763 entries, 0 to 101765\n",
      "Columns: 147 entries, encounter_id to count_E990_E999\n",
      "dtypes: bool(4), float64(6), int64(115), object(22)\n",
      "memory usage: 112.2+ MB\n"
     ]
    }
   ],
   "source": [
    "random_forests.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa3b56",
   "metadata": {
    "papermill": {
     "duration": 0.001356,
     "end_time": "2025-07-07T15:27:54.690964",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.689608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Memory Optimization\n",
    "\n",
    "The `optimize_dtypes()` function reduces memory usage by downcasting numeric types to their smallest sufficient representation:\n",
    "- `int64` → `int8/int16/int32` based on value ranges\n",
    "- `float64` → `float32` when precision allows\n",
    "\n",
    "This optimization is particularly valuable for large datasets and memory-intensive operations like SMOTE resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ecebe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.693970Z",
     "iopub.status.busy": "2025-07-07T15:27:54.693881Z",
     "iopub.status.idle": "2025-07-07T15:27:54.696620Z",
     "shell.execute_reply": "2025-07-07T15:27:54.696414Z"
    },
    "papermill": {
     "duration": 0.004909,
     "end_time": "2025-07-07T15:27:54.697193",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.692284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_dtypes(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we convert some of our columns intelligently to save on memory & time\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type == 'int64':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "\n",
    "        elif col_type == 'float64':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fed952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.700216Z",
     "iopub.status.busy": "2025-07-07T15:27:54.700139Z",
     "iopub.status.idle": "2025-07-07T15:27:54.716815Z",
     "shell.execute_reply": "2025-07-07T15:27:54.716579Z"
    },
    "papermill": {
     "duration": 0.018938,
     "end_time": "2025-07-07T15:27:54.717480",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.698542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_forests = optimize_dtypes(random_forests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5dd62ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.721081Z",
     "iopub.status.busy": "2025-07-07T15:27:54.720997Z",
     "iopub.status.idle": "2025-07-07T15:27:54.724734Z",
     "shell.execute_reply": "2025-07-07T15:27:54.724526Z"
    },
    "papermill": {
     "duration": 0.006135,
     "end_time": "2025-07-07T15:27:54.725282",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.719147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 101763 entries, 0 to 101765\n",
      "Columns: 147 entries, encounter_id to count_E990_E999\n",
      "dtypes: bool(4), float32(6), int16(1), int32(2), int8(112), object(22)\n",
      "memory usage: 32.4+ MB\n"
     ]
    }
   ],
   "source": [
    "random_forests.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0772da35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.728293Z",
     "iopub.status.busy": "2025-07-07T15:27:54.728213Z",
     "iopub.status.idle": "2025-07-07T15:27:54.937602Z",
     "shell.execute_reply": "2025-07-07T15:27:54.937389Z"
    },
    "papermill": {
     "duration": 0.21164,
     "end_time": "2025-07-07T15:27:54.938234",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.726594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62f592",
   "metadata": {
    "papermill": {
     "duration": 0.001435,
     "end_time": "2025-07-07T15:27:54.941281",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.939846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluation and Persistence Function\n",
    "\n",
    "The `evaluate_and_save_pipeline()` function provides standardized evaluation across all modeling approaches in this project:\n",
    "\n",
    "**Comprehensive Metrics Calculation:**\n",
    "- **Classification performance**: Accuracy, precision, recall, F1-score, specificity\n",
    "- **Probability-based metrics**: ROC curve data and AUC score for threshold optimization\n",
    "- **Confusion matrix**: True/false positive/negative counts for detailed performance analysis\n",
    "- **Prediction arrays**: Both binary predictions and probability scores for ensemble building\n",
    "\n",
    "**Standardized Output Format:**\n",
    "All metrics are saved in identical pickle format enabling:\n",
    "- Direct performance comparison across different model types\n",
    "- Consistent evaluation methodology regardless of underlying algorithm\n",
    "- Easy integration into ensemble methods and model selection workflows\n",
    "- Reproducible results with preserved prediction arrays\n",
    "\n",
    "**Model Persistence:**\n",
    "Trained pipelines are saved with preprocessing steps intact, ensuring deployment-ready models that can handle new data with the same\n",
    "transformations applied during training.\n",
    "\n",
    "This standardization is critical for fair model comparison and supports the ensemble modeling approach in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bebc450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.944966Z",
     "iopub.status.busy": "2025-07-07T15:27:54.944782Z",
     "iopub.status.idle": "2025-07-07T15:27:54.949416Z",
     "shell.execute_reply": "2025-07-07T15:27:54.949187Z"
    },
    "papermill": {
     "duration": 0.007363,
     "end_time": "2025-07-07T15:27:54.950033",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.942670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_and_save_pipeline(pipeline, namestring, token, \n",
    "                                X_train, X_test, \n",
    "                                y_train, y_test,\n",
    "                                console_out = False):\n",
    "    \"\"\"\n",
    "    Evaluates a trained pipeline and saves metrics to a pickle file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if any(v is None for v in [X_train, X_test, y_train, y_test]):\n",
    "        raise ValueError(\"X_train, X_test, y_train, or y_test must not be None.\")\n",
    "\n",
    "    # Convert to numpy if needed\n",
    "    y_train = y_train.values if hasattr(y_train, \"values\") else y_train\n",
    "    y_test = y_test.values if hasattr(y_test, \"values\") else y_test\n",
    "\n",
    "    # Make predictions once\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Get probability predictions\n",
    "    if hasattr(pipeline, \"predict_proba\"):\n",
    "        y_test_pred_pct = pipeline.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(pipeline, \"decision_function\"):\n",
    "        y_test_pred_pct = pipeline.decision_function(X_test)\n",
    "    else:\n",
    "        raise AttributeError(\"Pipeline needs predict_proba() or decision_function() for ROC/AUC.\")\n",
    "\n",
    "    # Classification metrics (not regression metrics)\n",
    "    accuracy = pipeline.score(X_test, y_test)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)  # Same as sensitivity\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    # Confusion matrix metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_pct)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Safe access to classes\n",
    "    classes_ = getattr(pipeline, 'classes_', np.unique(y_train))\n",
    "\n",
    "    # Save metrics\n",
    "    pickle_metrics = {\n",
    "        'model_version': f\"{token}_{namestring}\",\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'specificity': specificity,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_test': y_test,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'y_test_pred_proba': y_test_pred_pct,\n",
    "        'display_labels': classes_,\n",
    "        'confusion_matrix': {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp},\n",
    "        'roc_curve': {'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds},\n",
    "\n",
    "        # SHAP-specific additions\n",
    "        'shap_data': {\n",
    "            'model': pipeline,\n",
    "            'X_train_processed': pipeline.named_steps['preprocessor'].transform(X_train),\n",
    "            'X_test_processed': pipeline.named_steps['preprocessor'].transform(X_test),\n",
    "            'feature_names': pipeline.named_steps['preprocessor'].get_feature_names_out(),\n",
    "            'original_feature_names': list(X_train.columns)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save to file\n",
    "    filename = f\"../models/fits_pickle_{token}_{namestring}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(pickle_metrics, file)\n",
    "\n",
    "    if console_out:\n",
    "            # Print summary\n",
    "            print(f\"Metrics saved to {filename}\")\n",
    "            print(f'Accuracy:    {accuracy:.4f}')\n",
    "            print(f'Precision:   {precision:.4f}')\n",
    "            print(f'Recall:      {recall:.4f}')\n",
    "            print(f'F1-Score:    {f1:.4f}')\n",
    "            print(f'Specificity: {specificity:.4f}')\n",
    "            print(f'ROC AUC:     {roc_auc:.4f}')\n",
    "\n",
    "            # Plot confusion matrix\n",
    "            cm = confusion_matrix(y_test, y_test_pred)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes_)\n",
    "            disp.plot(cmap=plt.cm.Blues)\n",
    "            plt.title(f\"Confusion Matrix - {namestring}\")\n",
    "            plt.show()\n",
    "    \n",
    "    return pickle_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7e322a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.953239Z",
     "iopub.status.busy": "2025-07-07T15:27:54.953166Z",
     "iopub.status.idle": "2025-07-07T15:27:54.974332Z",
     "shell.execute_reply": "2025-07-07T15:27:54.974028Z"
    },
    "papermill": {
     "duration": 0.02358,
     "end_time": "2025-07-07T15:27:54.975100",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.951520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = random_forests.drop([\"readmitted\"], axis=1)\n",
    "y = random_forests[\"readmitted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71615d40",
   "metadata": {
    "papermill": {
     "duration": 0.001568,
     "end_time": "2025-07-07T15:27:54.978178",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.976610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Type Usage\n",
    "\n",
    "**exclude_features**: Used as a filter when defining the other feature types - ensures ID columns and target variable don't get included in modeling features.\n",
    "\n",
    "**numeric_features**:\n",
    "- Fed into \"passthrough\" in the ColumnTransformer preprocessor\n",
    "- Preserves original values without scaling (XGBoost handles different scales naturally)\n",
    "- These remain as continuous variables for tree splitting decisions\n",
    "\n",
    "**boolean_features**: \n",
    "- Combined with object_features and passed to OrdinalEncoder\n",
    "- Converted to integers (0, 1) rather than one-hot encoded\n",
    "- More efficient representation for tree-based models\n",
    "\n",
    "**object_features**: \n",
    "- Combined with boolean_features and passed to OrdinalEncoder  \n",
    "- Each category mapped to integer codes (0, 1, 2, ...)\n",
    "- `handle_unknown=\"use_encoded_value\", unknown_value=-1` handles unseen categories\n",
    "\n",
    "**Combined usage**:\n",
    "- ColumnTransformer applies different preprocessing: passthrough to numeric, OrdinalEncoder to categorical\n",
    "- No feature expansion - maintains original ~147 features (vs 2,871 with one-hot encoding)\n",
    "- `categorical_features` list tracks column indices for XGBoost's native categorical handling\n",
    "\n",
    "The separation optimizes preprocessing for tree-based learning - numeric features retain their distributions for optimal splits, while categorical features use compact ordinal encoding that XGBoost can efficiently partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91a6e160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.981443Z",
     "iopub.status.busy": "2025-07-07T15:27:54.981360Z",
     "iopub.status.idle": "2025-07-07T15:27:54.984953Z",
     "shell.execute_reply": "2025-07-07T15:27:54.984754Z"
    },
    "papermill": {
     "duration": 0.005888,
     "end_time": "2025-07-07T15:27:54.985517",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.979629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training features to include\n",
    "exclude_features = [\"patient_nbr\", \"encounter_id\", \"readmitted\"]\n",
    "numeric_features = [\n",
    "    col\n",
    "    for col in X.columns\n",
    "    if col not in exclude_features and pd.api.types.is_numeric_dtype(X[col])\n",
    "]\n",
    "boolean_features = [\n",
    "    col for col in X.columns if col not in exclude_features and X[col].dtype == \"bool\"\n",
    "]\n",
    "object_features = [\n",
    "    col for col in X.columns if col not in exclude_features and X[col].dtype == \"object\"\n",
    "]\n",
    "categorical_features = [\n",
    "    X.columns.get_loc(col) for col in object_features + boolean_features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e505246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:54.988819Z",
     "iopub.status.busy": "2025-07-07T15:27:54.988740Z",
     "iopub.status.idle": "2025-07-07T15:27:55.040085Z",
     "shell.execute_reply": "2025-07-07T15:27:55.039794Z"
    },
    "papermill": {
     "duration": 0.053882,
     "end_time": "2025-07-07T15:27:55.040859",
     "exception": false,
     "start_time": "2025-07-07T15:27:54.986977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=randy, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d07b98",
   "metadata": {
    "papermill": {
     "duration": 0.001449,
     "end_time": "2025-07-07T15:27:55.044081",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.042632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing with ColumnTransformer\n",
    "\n",
    "This applies XGBoost-optimized preprocessing that differs significantly from linear models:\n",
    "\n",
    "1. **\"num\" step**: Applies \"passthrough\" to numeric_features\n",
    "   - No scaling applied - XGBoost is invariant to monotonic transformations\n",
    "   - Preserves original value ranges and distributions\n",
    "   \n",
    "2. **\"cat\" step**: Applies OrdinalEncoder() to categorical features\n",
    "   - Converts categories to integers rather than one-hot encoding\n",
    "   - `handle_unknown=\"use_encoded_value\", unknown_value=-1`: Maps unseen categories to -1\n",
    "   - Much more efficient than one-hot encoding for tree-based models\n",
    "   - Preserves ordinality where it exists naturally\n",
    "\n",
    "Why This Approach for XGBoost:\n",
    "- Tree-based models split on single feature values, making ordinal encoding optimal\n",
    "- Avoids the curse of dimensionality from one-hot encoding (~147 features vs 2,871)\n",
    "- XGBoost can learn optimal splits regardless of numeric scale\n",
    "- Missing value encoding (-1) allows XGBoost's native missing value handling to work effectively\n",
    "\n",
    "The result is a compact, efficient feature representation optimized for gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a37ba331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:55.047323Z",
     "iopub.status.busy": "2025-07-07T15:27:55.047240Z",
     "iopub.status.idle": "2025-07-07T15:27:55.049026Z",
     "shell.execute_reply": "2025-07-07T15:27:55.048816Z"
    },
    "papermill": {
     "duration": 0.004103,
     "end_time": "2025-07-07T15:27:55.049577",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.045474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor_xgb = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_features),  # Keep as-is\n",
    "        (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "        object_features + boolean_features)  # Encode multiple columns\n",
    "    ]\n",
    ")\n",
    "\n",
    "# This is also an option\n",
    "# preprocessor_xgb = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', MinMaxScaler(), numeric_features),\n",
    "#         ('cat', OneHotEncoder(drop='first', sparse_output=True, handle_unknown='ignore'), object_features)\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c07a4",
   "metadata": {
    "papermill": {
     "duration": 0.001456,
     "end_time": "2025-07-07T15:27:55.052506",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.051050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Preprocessing is done inside the pipeline to ensure consistent transformation between training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af9f7121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:55.055920Z",
     "iopub.status.busy": "2025-07-07T15:27:55.055844Z",
     "iopub.status.idle": "2025-07-07T15:27:55.086488Z",
     "shell.execute_reply": "2025-07-07T15:27:55.086263Z"
    },
    "papermill": {
     "duration": 0.033144,
     "end_time": "2025-07-07T15:27:55.087081",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.053937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaNs in categorical columns...\n",
      "No NaNs found in categorical columns - safe to train!\n"
     ]
    }
   ],
   "source": [
    "# Final check of NaN's before training\n",
    "print(\"Checking for NaNs in categorical columns...\")\n",
    "categorical_cols = object_features + boolean_features\n",
    "nan_check = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    nan_count = X[col].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        nan_check[col] = nan_count\n",
    "\n",
    "if nan_check:\n",
    "    print(\"STOP! Still have NaNs:\")\n",
    "    for col, count in nan_check.items():\n",
    "        print(f\"  {col}: {count} NaNs\")\n",
    "    print(\"\\nFill these before training!\")\n",
    "else:\n",
    "    print(\"No NaNs found in categorical columns - safe to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed7b8c",
   "metadata": {
    "papermill": {
     "duration": 0.001493,
     "end_time": "2025-07-07T15:27:55.090157",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.088664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Hyperparameter Search Strategy\n",
    "\n",
    "**Log-Scale Parameter Tuning:**\n",
    "Several hyperparameters are sampled on logarithmic scales using `log=True`:\n",
    "\n",
    "- `learning_rate` (0.001-1.0, log scale): Learning rates vary exponentially in effectiveness - the difference between 0.001 and 0.01 is as significant as between 0.1 and 1.0\n",
    "- `reg_lambda` & `reg_alpha` (0.001-1000, log scale): Regularization strength spans several orders of magnitude - linear sampling would oversample high values and miss important low-regularization regions\n",
    "\n",
    "**Why Log Scaling Matters:**\n",
    "- Even exploration: Ensures equal search attention across exponential ranges (e.g., 0.001, 0.01, 0.1, 1.0)\n",
    "- Efficient optimization: Optuna's TPE sampler works more effectively when parameter importance is evenly distributed\n",
    "- Practical relevance: Most ML hyperparameters exhibit exponential rather than linear sensitivity\n",
    "\n",
    "**Linear vs Categorical Parameters:**\n",
    "- `subsample`, `colsample_bytree`: Linear scale (0.5-1.0) as effects are more uniform across this range\n",
    "- `n_estimators`, `max_depth`: Integer ranges where each increment has roughly equal impact\n",
    "- `scale_pos_weight`: Categorical values based on class ratio multiples\n",
    "\n",
    "This mixed approach optimizes search efficiency while respecting the natural scaling properties of each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5afad969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:55.093503Z",
     "iopub.status.busy": "2025-07-07T15:27:55.093425Z",
     "iopub.status.idle": "2025-07-07T15:27:55.095983Z",
     "shell.execute_reply": "2025-07-07T15:27:55.095795Z"
    },
    "papermill": {
     "duration": 0.004891,
     "end_time": "2025-07-07T15:27:55.096484",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.091593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to search\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 25),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 1.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.3, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.3, 1.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0001, 100, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0001, 100, log=True),\n",
    "        'scale_pos_weight': trial.suggest_int('scale_pos_weight', 1, 3),\n",
    "        'random_state': randy,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "\n",
    "    # Preprocess the entire training set once\n",
    "    X_train_proc = preprocessor_xgb.fit_transform(X_train)\n",
    "\n",
    "    # Create DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train_proc, label=y_train)\n",
    "\n",
    "    # Use xgboost.cv with pruning callback\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=params['n_estimators'],\n",
    "        nfold=5,\n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        seed=randy,\n",
    "        early_stopping_rounds=10,\n",
    "        callbacks=[XGBoostPruningCallback(trial, 'test-auc')]\n",
    "    )\n",
    "\n",
    "    # Return the best CV score\n",
    "    return cv_results['test-auc-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afae8b7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:55.099736Z",
     "iopub.status.busy": "2025-07-07T15:27:55.099664Z",
     "iopub.status.idle": "2025-07-07T15:27:55.101408Z",
     "shell.execute_reply": "2025-07-07T15:27:55.101231Z"
    },
    "papermill": {
     "duration": 0.004018,
     "end_time": "2025-07-07T15:27:55.101982",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.097964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callbacks for monitoring\n",
    "def print_best_callback(study, trial):\n",
    "    print(f\"Trial {trial.number}: {trial.value:.4f} (best: {study.best_value:.4f})\")\n",
    "\n",
    "def save_best_callback(study, trial):\n",
    "    if study.best_trial == trial:\n",
    "        # Save best params so far\n",
    "        with open(f\"../models/{token}_XGB_best_params.pkl\", \"wb\") as f:\n",
    "            pickle.dump(study.best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85643d7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:55.105375Z",
     "iopub.status.busy": "2025-07-07T15:27:55.105294Z",
     "iopub.status.idle": "2025-07-07T15:35:13.739662Z",
     "shell.execute_reply": "2025-07-07T15:35:13.739372Z"
    },
    "papermill": {
     "duration": 438.637004,
     "end_time": "2025-07-07T15:35:13.740473",
     "exception": false,
     "start_time": "2025-07-07T15:27:55.103469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 10:27:55,106] A new study created in memory with name: no-name-97ab2362-56cf-448b-b95f-506c0a5a2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 10:28:11,360] Trial 0 finished with value: 0.6972604576481944 and parameters: {'n_estimators': 313, 'min_child_weight': 12, 'max_depth': 3, 'learning_rate': 0.7280849356408012, 'subsample': 0.6032474611442811, 'colsample_bytree': 0.34577546110928736, 'reg_lambda': 1.0564256819169864, 'reg_alpha': 0.00014743110884121556, 'scale_pos_weight': 3}. Best is trial 0 with value: 0.6972604576481944.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 398: 0.7058 (best: 0.7087)\n",
      "Best parameters: {'n_estimators': 415, 'min_child_weight': 10, 'max_depth': 9, 'learning_rate': 0.13511513493878266, 'subsample': 0.8074358236796195, 'colsample_bytree': 0.3361691464685002, 'reg_lambda': 3.2319036037247653, 'reg_alpha': 15.420312161747052, 'scale_pos_weight': 2}\n",
      "Best AUC: 0.7087\n",
      "CPU times: user 38min 35s, sys: 9min 48s, total: 48min 23s\n",
      "Wall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create study with pruner\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner= MedianPruner(n_startup_trials=5, n_warmup_steps=10),\n",
    "    sampler=TPESampler(seed=randy)\n",
    ")\n",
    "\n",
    "# Run with callbacks\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=400, \n",
    "    callbacks=[print_best_callback, save_best_callback],\n",
    "    n_jobs=-1,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "# After study.optimize() completes\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best AUC: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b7b9857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:35:13.772179Z",
     "iopub.status.busy": "2025-07-07T15:35:13.772060Z",
     "iopub.status.idle": "2025-07-07T15:35:16.963363Z",
     "shell.execute_reply": "2025-07-07T15:35:16.963088Z"
    },
    "papermill": {
     "duration": 3.207102,
     "end_time": "2025-07-07T15:35:16.963998",
     "exception": false,
     "start_time": "2025-07-07T15:35:13.756896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ../models/f11_XGB_final.pkl\n"
     ]
    }
   ],
   "source": [
    "xgb_final = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_xgb), \n",
    "    ('model', XGBClassifier(**best_params, eval_metric='logloss', random_state=randy))  \n",
    "])\n",
    "\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "filename=f\"../models/{token}_XGB_final.pkl\"\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(xgb_final, file)\n",
    "print(f\"Model saved as {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2e1f62",
   "metadata": {
    "papermill": {
     "duration": 0.014049,
     "end_time": "2025-07-07T15:35:16.992932",
     "exception": false,
     "start_time": "2025-07-07T15:35:16.978883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final XGBoost Pipeline and Evaluation\n",
    "\n",
    "**Pipeline Components:**\n",
    "This final pipeline combines preprocessing and the optimized XGBoost model:\n",
    "1. **Preprocessing**: Ordinal encoding for categoricals + passthrough for numerics (147 features preserved)\n",
    "2. **XGBoost Model**: Gradient boosting with optimized hyperparameters across 9 key parameters for ensemble learning\n",
    "\n",
    "**Model Persistence:**\n",
    "The complete pipeline is saved as `{token}_XGB_final.pkl`, preserving both the fitted preprocessor and trained model for deployment.\n",
    "\n",
    "**Standardized Evaluation:**\n",
    "The `evaluate_and_save_pipeline()` function generates comprehensive metrics in the same format used across all models in this project, enabling direct performance comparison with linear models and supporting ensemble model development in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24a91ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:35:17.021037Z",
     "iopub.status.busy": "2025-07-07T15:35:17.020940Z",
     "iopub.status.idle": "2025-07-07T15:35:17.022549Z",
     "shell.execute_reply": "2025-07-07T15:35:17.022312Z"
    },
    "papermill": {
     "duration": 0.016344,
     "end_time": "2025-07-07T15:35:17.023180",
     "exception": false,
     "start_time": "2025-07-07T15:35:17.006836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open a trained model\n",
    "# xgb_final = pd.read_pickle(\"../models/f04_XGB_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7e4df9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:35:17.050320Z",
     "iopub.status.busy": "2025-07-07T15:35:17.050227Z",
     "iopub.status.idle": "2025-07-07T15:35:18.735052Z",
     "shell.execute_reply": "2025-07-07T15:35:18.734794Z"
    },
    "papermill": {
     "duration": 1.699089,
     "end_time": "2025-07-07T15:35:18.735706",
     "exception": false,
     "start_time": "2025-07-07T15:35:17.036617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_version': 'f11_XGBoost',\n",
       " 'accuracy': 0.6094924581142829,\n",
       " 'precision': 0.5509637954335301,\n",
       " 'recall': 0.8257115446114487,\n",
       " 'f1_score': 0.6609215017064847,\n",
       " 'specificity': np.float64(0.4246263215457528),\n",
       " 'roc_auc': np.float64(0.7052126619520076),\n",
       " 'y_test': array([1, 0, 0, ..., 1, 1, 0], dtype=int8),\n",
       " 'y_train_pred': array([1, 0, 1, ..., 0, 1, 1]),\n",
       " 'y_test_pred': array([1, 1, 1, ..., 1, 1, 1]),\n",
       " 'y_test_pred_proba': array([0.62125766, 0.86658746, 0.8027118 , ..., 0.7682214 , 0.74429685,\n",
       "        0.51019704], dtype=float32),\n",
       " 'display_labels': array([0, 1]),\n",
       " 'confusion_matrix': {'tn': np.int64(4659),\n",
       "  'fp': np.int64(6313),\n",
       "  'fn': np.int64(1635),\n",
       "  'tp': np.int64(7746)},\n",
       " 'roc_curve': {'fpr': array([0.        , 0.        , 0.        , ..., 0.97156398, 0.97156398,\n",
       "         1.        ]),\n",
       "  'tpr': array([0.00000000e+00, 1.06598444e-04, 1.17258288e-03, ...,\n",
       "         9.99893402e-01, 1.00000000e+00, 1.00000000e+00]),\n",
       "  'thresholds': array([       inf, 0.9870635 , 0.97624785, ..., 0.04520348, 0.0449166 ,\n",
       "         0.00497846], dtype=float32)},\n",
       " 'shap_data': {'model': Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num', 'passthrough',\n",
       "                                                    ['age', 'admission_type_id',\n",
       "                                                     'discharge_disposition_id',\n",
       "                                                     'admission_source_id',\n",
       "                                                     'time_in_hospital',\n",
       "                                                     'num_lab_procedures',\n",
       "                                                     'num_procedures',\n",
       "                                                     'num_medications',\n",
       "                                                     'number_outpatient',\n",
       "                                                     'number_emergency',\n",
       "                                                     'number_inpatient',\n",
       "                                                     'number_diagnoses', 'change',\n",
       "                                                     'diabetesMed', 'A1C_tested',\n",
       "                                                     '...\n",
       "                                 gamma=None, grow_policy=None,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=None,\n",
       "                                 learning_rate=0.13511513493878266, max_bin=None,\n",
       "                                 max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                                 max_delta_step=None, max_depth=9,\n",
       "                                 max_leaves=None, min_child_weight=10,\n",
       "                                 missing=nan, monotone_constraints=None,\n",
       "                                 multi_strategy=None, n_estimators=415,\n",
       "                                 n_jobs=None, num_parallel_tree=None, ...))]),\n",
       "  'X_train_processed': array([[90, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "         [50, 3, 1, ..., 0.0, 0.0, 0.0],\n",
       "         [80, 2, 6, ..., 1.0, 0.0, 1.0],\n",
       "         ...,\n",
       "         [50, 1, 1, ..., 1.0, 0.0, 0.0],\n",
       "         [90, 1, 18, ..., 1.0, 0.0, 1.0],\n",
       "         [70, 3, 6, ..., 0.0, 0.0, 0.0]], dtype=object),\n",
       "  'X_test_processed': array([[60, 1, 1, ..., 1.0, 1.0, 0.0],\n",
       "         [70, 1, 1, ..., 1.0, 0.0, 0.0],\n",
       "         [80, 1, 1, ..., 0.0, 0.0, 0.0],\n",
       "         ...,\n",
       "         [60, 1, 18, ..., 1.0, 0.0, 0.0],\n",
       "         [80, 1, 3, ..., 1.0, 0.0, 0.0],\n",
       "         [80, 3, 18, ..., 1.0, 1.0, 1.0]], dtype=object),\n",
       "  'feature_names': array(['num__age', 'num__admission_type_id',\n",
       "         'num__discharge_disposition_id', 'num__admission_source_id',\n",
       "         'num__time_in_hospital', 'num__num_lab_procedures',\n",
       "         'num__num_procedures', 'num__num_medications',\n",
       "         'num__number_outpatient', 'num__number_emergency',\n",
       "         'num__number_inpatient', 'num__number_diagnoses', 'num__change',\n",
       "         'num__diabetesMed', 'num__A1C_tested', 'num__service_utilization',\n",
       "         'num__substitution', 'num__med_change_count',\n",
       "         'num__diabetes_meds_used', 'num__num_nondiabetic_medications',\n",
       "         'num__has_001_139', 'num__has_140_239', 'num__has_240_279',\n",
       "         'num__has_280_289', 'num__has_290_319', 'num__has_320_389',\n",
       "         'num__has_390_459', 'num__has_460_519', 'num__has_520_579',\n",
       "         'num__has_580_629', 'num__has_630_679', 'num__has_680_709',\n",
       "         'num__has_710_739', 'num__has_740_759', 'num__has_760_779',\n",
       "         'num__has_780_799', 'num__has_800_999', 'num__has_V01_V06',\n",
       "         'num__has_V07_V09', 'num__has_V10_V19', 'num__has_V20_V29',\n",
       "         'num__has_V30_V39', 'num__has_V40_V49', 'num__has_V50_V59',\n",
       "         'num__has_V60_V69', 'num__has_V70_V82', 'num__has_V83_V84',\n",
       "         'num__has_E979', 'num__has_E849', 'num__has_E800_E807',\n",
       "         'num__has_E810_E819', 'num__has_E820_E825', 'num__has_E826_E829',\n",
       "         'num__has_E830_E838', 'num__has_E840_E845', 'num__has_E846_E848',\n",
       "         'num__has_E850_E858', 'num__has_E860_E869', 'num__has_E870_E876',\n",
       "         'num__has_E878_E879', 'num__has_E880_E888', 'num__has_E890_E899',\n",
       "         'num__has_E900_E909', 'num__has_E910_E915', 'num__has_E916_E928',\n",
       "         'num__has_E930_E949', 'num__has_E950_E959', 'num__has_E960_E969',\n",
       "         'num__has_E970_E978', 'num__has_E980_E989', 'num__has_E990_E999',\n",
       "         'num__count_001_139', 'num__count_140_239', 'num__count_240_279',\n",
       "         'num__count_280_289', 'num__count_290_319', 'num__count_320_389',\n",
       "         'num__count_390_459', 'num__count_460_519', 'num__count_520_579',\n",
       "         'num__count_580_629', 'num__count_630_679', 'num__count_680_709',\n",
       "         'num__count_710_739', 'num__count_740_759', 'num__count_760_779',\n",
       "         'num__count_780_799', 'num__count_800_999', 'num__count_V01_V06',\n",
       "         'num__count_V07_V09', 'num__count_V10_V19', 'num__count_V20_V29',\n",
       "         'num__count_V30_V39', 'num__count_V40_V49', 'num__count_V50_V59',\n",
       "         'num__count_V60_V69', 'num__count_V70_V82', 'num__count_V83_V84',\n",
       "         'num__count_E979', 'num__count_E849', 'num__count_E800_E807',\n",
       "         'num__count_E810_E819', 'num__count_E820_E825',\n",
       "         'num__count_E826_E829', 'num__count_E830_E838',\n",
       "         'num__count_E840_E845', 'num__count_E846_E848',\n",
       "         'num__count_E850_E858', 'num__count_E860_E869',\n",
       "         'num__count_E870_E876', 'num__count_E878_E879',\n",
       "         'num__count_E880_E888', 'num__count_E890_E899',\n",
       "         'num__count_E900_E909', 'num__count_E910_E915',\n",
       "         'num__count_E916_E928', 'num__count_E930_E949',\n",
       "         'num__count_E950_E959', 'num__count_E960_E969',\n",
       "         'num__count_E970_E978', 'num__count_E980_E989',\n",
       "         'num__count_E990_E999', 'cat__race', 'cat__gender',\n",
       "         'cat__medical_specialty', 'cat__diag_1', 'cat__diag_2',\n",
       "         'cat__diag_3', 'cat__max_glu_serum', 'cat__A1Cresult',\n",
       "         'cat__metformin', 'cat__chlorpropamide', 'cat__glimepiride',\n",
       "         'cat__glipizide', 'cat__glyburide', 'cat__pioglitazone',\n",
       "         'cat__rosiglitazone', 'cat__tolazamide', 'cat__insulin',\n",
       "         'cat__glyburide-metformin', 'cat__medical_subspecialty',\n",
       "         'cat__discharge_disposition_group', 'cat__admission_source_group',\n",
       "         'cat__age_group', 'cat__change', 'cat__diabetesMed',\n",
       "         'cat__A1C_tested', 'cat__substitution'], dtype=object),\n",
       "  'original_feature_names': ['encounter_id',\n",
       "   'patient_nbr',\n",
       "   'race',\n",
       "   'gender',\n",
       "   'age',\n",
       "   'admission_type_id',\n",
       "   'discharge_disposition_id',\n",
       "   'admission_source_id',\n",
       "   'time_in_hospital',\n",
       "   'medical_specialty',\n",
       "   'num_lab_procedures',\n",
       "   'num_procedures',\n",
       "   'num_medications',\n",
       "   'number_outpatient',\n",
       "   'number_emergency',\n",
       "   'number_inpatient',\n",
       "   'diag_1',\n",
       "   'diag_2',\n",
       "   'diag_3',\n",
       "   'number_diagnoses',\n",
       "   'max_glu_serum',\n",
       "   'A1Cresult',\n",
       "   'metformin',\n",
       "   'chlorpropamide',\n",
       "   'glimepiride',\n",
       "   'glipizide',\n",
       "   'glyburide',\n",
       "   'pioglitazone',\n",
       "   'rosiglitazone',\n",
       "   'tolazamide',\n",
       "   'insulin',\n",
       "   'glyburide-metformin',\n",
       "   'change',\n",
       "   'diabetesMed',\n",
       "   'medical_subspecialty',\n",
       "   'discharge_disposition_group',\n",
       "   'admission_source_group',\n",
       "   'A1C_tested',\n",
       "   'service_utilization',\n",
       "   'substitution',\n",
       "   'med_change_count',\n",
       "   'diabetes_meds_used',\n",
       "   'num_nondiabetic_medications',\n",
       "   'age_group',\n",
       "   'has_001_139',\n",
       "   'has_140_239',\n",
       "   'has_240_279',\n",
       "   'has_280_289',\n",
       "   'has_290_319',\n",
       "   'has_320_389',\n",
       "   'has_390_459',\n",
       "   'has_460_519',\n",
       "   'has_520_579',\n",
       "   'has_580_629',\n",
       "   'has_630_679',\n",
       "   'has_680_709',\n",
       "   'has_710_739',\n",
       "   'has_740_759',\n",
       "   'has_760_779',\n",
       "   'has_780_799',\n",
       "   'has_800_999',\n",
       "   'has_V01_V06',\n",
       "   'has_V07_V09',\n",
       "   'has_V10_V19',\n",
       "   'has_V20_V29',\n",
       "   'has_V30_V39',\n",
       "   'has_V40_V49',\n",
       "   'has_V50_V59',\n",
       "   'has_V60_V69',\n",
       "   'has_V70_V82',\n",
       "   'has_V83_V84',\n",
       "   'has_E979',\n",
       "   'has_E849',\n",
       "   'has_E800_E807',\n",
       "   'has_E810_E819',\n",
       "   'has_E820_E825',\n",
       "   'has_E826_E829',\n",
       "   'has_E830_E838',\n",
       "   'has_E840_E845',\n",
       "   'has_E846_E848',\n",
       "   'has_E850_E858',\n",
       "   'has_E860_E869',\n",
       "   'has_E870_E876',\n",
       "   'has_E878_E879',\n",
       "   'has_E880_E888',\n",
       "   'has_E890_E899',\n",
       "   'has_E900_E909',\n",
       "   'has_E910_E915',\n",
       "   'has_E916_E928',\n",
       "   'has_E930_E949',\n",
       "   'has_E950_E959',\n",
       "   'has_E960_E969',\n",
       "   'has_E970_E978',\n",
       "   'has_E980_E989',\n",
       "   'has_E990_E999',\n",
       "   'count_001_139',\n",
       "   'count_140_239',\n",
       "   'count_240_279',\n",
       "   'count_280_289',\n",
       "   'count_290_319',\n",
       "   'count_320_389',\n",
       "   'count_390_459',\n",
       "   'count_460_519',\n",
       "   'count_520_579',\n",
       "   'count_580_629',\n",
       "   'count_630_679',\n",
       "   'count_680_709',\n",
       "   'count_710_739',\n",
       "   'count_740_759',\n",
       "   'count_760_779',\n",
       "   'count_780_799',\n",
       "   'count_800_999',\n",
       "   'count_V01_V06',\n",
       "   'count_V07_V09',\n",
       "   'count_V10_V19',\n",
       "   'count_V20_V29',\n",
       "   'count_V30_V39',\n",
       "   'count_V40_V49',\n",
       "   'count_V50_V59',\n",
       "   'count_V60_V69',\n",
       "   'count_V70_V82',\n",
       "   'count_V83_V84',\n",
       "   'count_E979',\n",
       "   'count_E849',\n",
       "   'count_E800_E807',\n",
       "   'count_E810_E819',\n",
       "   'count_E820_E825',\n",
       "   'count_E826_E829',\n",
       "   'count_E830_E838',\n",
       "   'count_E840_E845',\n",
       "   'count_E846_E848',\n",
       "   'count_E850_E858',\n",
       "   'count_E860_E869',\n",
       "   'count_E870_E876',\n",
       "   'count_E878_E879',\n",
       "   'count_E880_E888',\n",
       "   'count_E890_E899',\n",
       "   'count_E900_E909',\n",
       "   'count_E910_E915',\n",
       "   'count_E916_E928',\n",
       "   'count_E930_E949',\n",
       "   'count_E950_E959',\n",
       "   'count_E960_E969',\n",
       "   'count_E970_E978',\n",
       "   'count_E980_E989',\n",
       "   'count_E990_E999']}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_save_pipeline(\n",
    "    pipeline=xgb_final, \n",
    "    namestring='XGBoost',\n",
    "    token=token, \n",
    "    X_train=X_train, \n",
    "    X_test=X_test, \n",
    "    y_train=y_train, \n",
    "    y_test=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 445.998915,
   "end_time": "2025-07-07T15:35:19.072064",
   "environment_variables": {},
   "exception": null,
   "input_path": "p04_xgboost.ipynb",
   "output_path": "outputs/p04_xgboost_executed.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T15:27:53.073149",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}