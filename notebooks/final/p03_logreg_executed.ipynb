{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672c26e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:35.885514Z",
     "iopub.status.busy": "2025-07-07T14:02:35.885108Z",
     "iopub.status.idle": "2025-07-07T14:02:35.893357Z",
     "shell.execute_reply": "2025-07-07T14:02:35.892950Z"
    },
    "papermill": {
     "duration": 0.01738,
     "end_time": "2025-07-07T14:02:35.894339",
     "exception": false,
     "start_time": "2025-07-07T14:02:35.876959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Available memory before training: 6.24 GB\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "\n",
    "import psutil\n",
    "print(f\"Available memory before training: {psutil.virtual_memory().available / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f27f22",
   "metadata": {
    "papermill": {
     "duration": 0.003064,
     "end_time": "2025-07-07T14:02:35.902415",
     "exception": false,
     "start_time": "2025-07-07T14:02:35.899351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Diabetes Readmission – Logistic Regression with Regularization \n",
    " \n",
    "## Introduction \n",
    " \n",
    "This notebook implements logistic regression models with L1 (Lasso) and L1+L2 (Elastic Net) regularization for predicting hospital readmission within 30 days for diabetic patients. We use the preprocessed dataset created in the previous notebook, which includes: \n",
    " \n",
    "- **Statistical independence**: First encounter per patient only (71,518 patients) to meet logistic regression assumptions \n",
    "- **Diagnostic code consolidation**: ICD-9 codes grouped into high-level categories rather than one-hot encoded \n",
    "- **Box-Cox transformations**: Applied to skewed numeric features for better linear model performance \n",
    "- **Engineered features**: Service utilization scores, medication changes, and discharge groupings \n",
    " \n",
    "## Methodology \n",
    " \n",
    "**Class Imbalance Handling**: We use SMOTENC (Synthetic Minority Oversampling Technique for Categorical) to address the class imbalance in readmission outcomes, generating synthetic minority class examples while preserving the categorical nature of our features. \n",
    " \n",
    "**Regularization Approaches**: \n",
    "1. **Lasso (L1)**: Performs automatic feature selection by driving coefficients to zero \n",
    "2. **Elastic Net**: Combines L1 and L2 penalties, balancing feature selection with coefficient shrinkage \n",
    " \n",
    "**Hyperparameter Optimization**: Optuna's Bayesian optimization efficiently searches the regularization parameter space, significantly more effective than traditional grid search for these high-dimensional problems. \n",
    " \n",
    "**Preprocessing Pipeline**: MinMax scaling for numeric features and one-hot encoding for categorical features, resulting in ~2,900 features after expansion. \n",
    " \n",
    "The goal is to build interpretable models that can identify key predictors of readmission while maintaining good predictive performance through proper regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72323dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:35.908649Z",
     "iopub.status.busy": "2025-07-07T14:02:35.908416Z",
     "iopub.status.idle": "2025-07-07T14:02:36.713625Z",
     "shell.execute_reply": "2025-07-07T14:02:36.713292Z"
    },
    "papermill": {
     "duration": 0.809293,
     "end_time": "2025-07-07T14:02:36.714437",
     "exception": false,
     "start_time": "2025-07-07T14:02:35.905144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9647cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:36.718612Z",
     "iopub.status.busy": "2025-07-07T14:02:36.718479Z",
     "iopub.status.idle": "2025-07-07T14:02:36.757524Z",
     "shell.execute_reply": "2025-07-07T14:02:36.757233Z"
    },
    "papermill": {
     "duration": 0.04202,
     "end_time": "2025-07-07T14:02:36.758221",
     "exception": false,
     "start_time": "2025-07-07T14:02:36.716201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = 'f11' # iteratable by the user as we try new things\n",
    "randy = 42 # random value insertion for repeatability\n",
    "log_reg = pd.read_pickle(\"../models/logReg.pkl\") # See prior notebook, p02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8667341f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:36.761836Z",
     "iopub.status.busy": "2025-07-07T14:02:36.761716Z",
     "iopub.status.idle": "2025-07-07T14:02:36.774516Z",
     "shell.execute_reply": "2025-07-07T14:02:36.774262Z"
    },
    "papermill": {
     "duration": 0.015288,
     "end_time": "2025-07-07T14:02:36.775160",
     "exception": false,
     "start_time": "2025-07-07T14:02:36.759872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fill all categorical NaNs\n",
    "\n",
    "categorical_cols_with_nans = [\n",
    "    \"primary_group\",\n",
    "    \"primary_subgroup\",\n",
    "    \"secondary_group\",\n",
    "    \"secondary_subgroup\",\n",
    "    \"secondary2_group\",\n",
    "    \"secondary2_subgroup\",\n",
    "]\n",
    "\n",
    "for col in categorical_cols_with_nans:\n",
    "    log_reg[col] = log_reg[col].fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92110419",
   "metadata": {
    "papermill": {
     "duration": 0.001542,
     "end_time": "2025-07-07T14:02:36.778274",
     "exception": false,
     "start_time": "2025-07-07T14:02:36.776732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Memory Optimization\n",
    "\n",
    "The `optimize_dtypes()` function reduces memory usage by downcasting numeric types to their smallest sufficient representation:\n",
    "- `int64` → `int8/int16/int32` based on value ranges\n",
    "- `float64` → `float32` when precision allows\n",
    "\n",
    "This optimization is particularly valuable for large datasets and memory-intensive operations like SMOTE resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d738358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:36.781890Z",
     "iopub.status.busy": "2025-07-07T14:02:36.781815Z",
     "iopub.status.idle": "2025-07-07T14:02:36.784341Z",
     "shell.execute_reply": "2025-07-07T14:02:36.784157Z"
    },
    "papermill": {
     "duration": 0.005194,
     "end_time": "2025-07-07T14:02:36.784946",
     "exception": false,
     "start_time": "2025-07-07T14:02:36.779752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_dtypes(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we convert some of our columns to save on memory & time\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type == 'int64':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "\n",
    "        elif col_type == 'float64':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562f408c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:36.788492Z",
     "iopub.status.busy": "2025-07-07T14:02:36.788406Z",
     "iopub.status.idle": "2025-07-07T14:02:36.793057Z",
     "shell.execute_reply": "2025-07-07T14:02:36.792819Z"
    },
    "papermill": {
     "duration": 0.007114,
     "end_time": "2025-07-07T14:02:36.793655",
     "exception": false,
     "start_time": "2025-07-07T14:02:36.786541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "log_reg = optimize_dtypes(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a89a5a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:36.797266Z",
     "iopub.status.busy": "2025-07-07T14:02:36.797193Z",
     "iopub.status.idle": "2025-07-07T14:02:37.138664Z",
     "shell.execute_reply": "2025-07-07T14:02:37.138434Z"
    },
    "papermill": {
     "duration": 0.344056,
     "end_time": "2025-07-07T14:02:37.139303",
     "exception": false,
     "start_time": "2025-07-07T14:02:36.795247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155489e2",
   "metadata": {
    "papermill": {
     "duration": 0.001577,
     "end_time": "2025-07-07T14:02:37.142644",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.141067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluation and Persistence Function\n",
    "\n",
    "The `evaluate_and_save_pipeline()` function provides standardized evaluation across all modeling approaches in this project:\n",
    "\n",
    "**Comprehensive Metrics Calculation:**\n",
    "- **Classification performance**: Accuracy, precision, recall, F1-score, specificity\n",
    "- **Probability-based metrics**: ROC curve data and AUC score for threshold optimization\n",
    "- **Confusion matrix**: True/false positive/negative counts for detailed performance analysis\n",
    "- **Prediction arrays**: Both binary predictions and probability scores for ensemble building\n",
    "\n",
    "**Standardized Output Format:**\n",
    "All metrics are saved in identical pickle format enabling:\n",
    "- Direct performance comparison across different model types\n",
    "- Consistent evaluation methodology regardless of underlying algorithm\n",
    "- Easy integration into ensemble methods and model selection workflows\n",
    "- Reproducible results with preserved prediction arrays\n",
    "\n",
    "**Model Persistence:**\n",
    "Trained pipelines are saved with preprocessing steps intact, ensuring deployment-ready models that can handle new data with the same\n",
    "transformations applied during training.\n",
    "\n",
    "This standardization is critical for fair model comparison and supports the ensemble modeling approach in later notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec64942",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:37.146397Z",
     "iopub.status.busy": "2025-07-07T14:02:37.146253Z",
     "iopub.status.idle": "2025-07-07T14:02:37.151051Z",
     "shell.execute_reply": "2025-07-07T14:02:37.150838Z"
    },
    "papermill": {
     "duration": 0.007407,
     "end_time": "2025-07-07T14:02:37.151681",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.144274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_and_save_pipeline(pipeline, namestring, token, \n",
    "                                X_train, X_test, \n",
    "                                y_train, y_test, \n",
    "                                console_out = False):\n",
    "    \"\"\"\n",
    "    Evaluates a trained pipeline and saves metrics to a pickle file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input validation\n",
    "    if any(v is None for v in [X_train, X_test, y_train, y_test]):\n",
    "        raise ValueError(\"X_train, X_test, y_train, or y_test must not be None.\")\n",
    "\n",
    "    # Convert to numpy if needed\n",
    "    y_train = y_train.values if hasattr(y_train, \"values\") else y_train\n",
    "    y_test = y_test.values if hasattr(y_test, \"values\") else y_test\n",
    "\n",
    "    # Make predictions once\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Get probability predictions\n",
    "    if hasattr(pipeline, \"predict_proba\"):\n",
    "        y_test_pred_pct = pipeline.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(pipeline, \"decision_function\"):\n",
    "        y_test_pred_pct = pipeline.decision_function(X_test)\n",
    "    else:\n",
    "        raise AttributeError(\"Pipeline needs predict_proba() or decision_function() for ROC/AUC.\")\n",
    "\n",
    "    # Classification metrics (not regression metrics)\n",
    "    accuracy = pipeline.score(X_test, y_test)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)  # Same as sensitivity\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    # Confusion matrix metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_pct)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Safe access to classes\n",
    "    classes_ = getattr(pipeline, 'classes_', np.unique(y_train))\n",
    "\n",
    "    # Save metrics\n",
    "    pickle_metrics = {\n",
    "        'model_version': f\"{token}_{namestring}\",\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'specificity': specificity,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_test': y_test,\n",
    "        'y_train_pred': y_train_pred,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'y_test_pred_proba': y_test_pred_pct,\n",
    "        'display_labels': classes_,\n",
    "        'confusion_matrix': {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp},\n",
    "        'roc_curve': {'fpr': fpr, 'tpr': tpr, 'thresholds': thresholds},\n",
    "\n",
    "        # SHAP-specific additions\n",
    "        'shap_data': {\n",
    "            'model': pipeline,\n",
    "            'X_train_processed': pipeline.named_steps['preprocessor'].transform(X_train),\n",
    "            'X_test_processed': pipeline.named_steps['preprocessor'].transform(X_test),\n",
    "            'feature_names': pipeline.named_steps['preprocessor'].get_feature_names_out(),\n",
    "            'original_feature_names': list(X_train.columns)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    filename = f\"../models/fits_pickle_{token}_{namestring}.pkl\"\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(pickle_metrics, file)\n",
    "\n",
    "    if console_out:\n",
    "        # Print summary\n",
    "        print(f\"Metrics saved to {filename}\")\n",
    "        print(f'Accuracy:    {accuracy:.4f}')\n",
    "        print(f'Precision:   {precision:.4f}')\n",
    "        print(f'Recall:      {recall:.4f}')\n",
    "        print(f'F1-Score:    {f1:.4f}')\n",
    "        print(f'Specificity: {specificity:.4f}')\n",
    "        print(f'ROC AUC:     {roc_auc:.4f}')\n",
    "\n",
    "        # Plot confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_test_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes_)\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title(f\"Confusion Matrix - {namestring}\")\n",
    "        plt.show()\n",
    "    \n",
    "    return pickle_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5604d924",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:37.155475Z",
     "iopub.status.busy": "2025-07-07T14:02:37.155403Z",
     "iopub.status.idle": "2025-07-07T14:02:37.164963Z",
     "shell.execute_reply": "2025-07-07T14:02:37.164757Z"
    },
    "papermill": {
     "duration": 0.012056,
     "end_time": "2025-07-07T14:02:37.165605",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.153549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = log_reg.drop([\"readmitted\"], axis=1)\n",
    "y = log_reg[\"readmitted\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef916cc",
   "metadata": {
    "papermill": {
     "duration": 0.001589,
     "end_time": "2025-07-07T14:02:37.169019",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.167430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Type Usage\n",
    "\n",
    "`exclude_features`: Used as a filter when defining the other feature types - ensures ID columns and target variable don't get included in modeling features.\n",
    "\n",
    "`numeric_features`:\n",
    "- Fed into the `MinMaxScaler` in the `ColumnTransformer` preprocessor\n",
    "- Scales values to `[0,1]` range for logistic regression\n",
    "- These remain as continuous variables (15 features)\n",
    "\n",
    "`boolean_features`:\n",
    "- Combined with `object_features` and passed to `OneHotEncoder`\n",
    "- Gets one-hot encoded despite being boolean (creates dummy variables)\n",
    "- Used in SMOTENC `categorical_features` index calculation\n",
    "\n",
    "`object_features`:\n",
    "- Combined with `boolean_features` and passed to `OneHotEncoder`\n",
    "- Creates dummy variables for each category (`drop=\"first\"` removes one for multicollinearity)\n",
    "- Used in SMOTENC `categorical_features` index calculation\n",
    "\n",
    "Combined usage:\n",
    "- `categorical_features = [X.columns.get_loc(col) for col in object_features + boolean_features]` creates column indices for SMOTENC to know which features are categorical\n",
    "- `ColumnTransformer` applies different preprocessing: `MinMaxScaler` to numeric, `OneHotEncoder` to categorical\n",
    "- Results in feature expansion from 50 → 2,871 features after one-hot encoding\n",
    "\n",
    "The separation allows proper preprocessing - continuous features get scaled, categorical features get encoded, and SMOTE knows which synthetic samples need categorical constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d9698c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:37.172516Z",
     "iopub.status.busy": "2025-07-07T14:02:37.172439Z",
     "iopub.status.idle": "2025-07-07T14:02:37.175135Z",
     "shell.execute_reply": "2025-07-07T14:02:37.174955Z"
    },
    "papermill": {
     "duration": 0.005111,
     "end_time": "2025-07-07T14:02:37.175675",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.170564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training features to include\n",
    "exclude_features = [\"patient_nbr\", \"encounter_id\", \"readmitted\"]\n",
    "numeric_features = [col for col in X.columns\n",
    "                    if col not in exclude_features and pd.api.types.is_numeric_dtype(X[col])\n",
    "]\n",
    "boolean_features = [col for col in X.columns \n",
    "                    if col not in exclude_features and X[col].dtype == \"bool\"\n",
    "]\n",
    "object_features = [col for col in X.columns \n",
    "                   if col not in exclude_features and X[col].dtype == \"object\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b58462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:37.179037Z",
     "iopub.status.busy": "2025-07-07T14:02:37.178956Z",
     "iopub.status.idle": "2025-07-07T14:02:37.195656Z",
     "shell.execute_reply": "2025-07-07T14:02:37.195439Z"
    },
    "papermill": {
     "duration": 0.019133,
     "end_time": "2025-07-07T14:02:37.196307",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.177174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=randy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0fa1c",
   "metadata": {
    "papermill": {
     "duration": 0.001623,
     "end_time": "2025-07-07T14:02:37.199826",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.198203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Handling class imbalance\n",
    "\n",
    "We'll use Synthetic Minority Oversampling Technique (SMOTE) to handle class imbalance issues. It's a method for handling imbalanced datasets by creating synthetic examples of the minority class rather than just duplicating existing ones. SMOTE generates new samples by interpolating between existing minority class samples and their nearest neighbors.\n",
    "\n",
    "SMOTE is only used for training, not for model application.\n",
    "\n",
    "### SMOTENC vs SMOTE: Handling Mixed Data Types\n",
    "\n",
    "**Why SMOTENC is Required:**\n",
    "\n",
    "Standard SMOTE (Synthetic Minority Oversampling Technique) only works with continuous numerical features. It generates synthetic samples by:\n",
    "1. Finding k-nearest neighbors of minority class samples\n",
    "2. Interpolating between a sample and its neighbors using linear combinations\n",
    "3. Creating new points along the line segments between samples\n",
    "\n",
    "**The Problem with Mixed Data Types:**\n",
    "Our dataset contains both continuous (age, time_in_hospital, num_medications) and categorical features (race, medical_specialty, A1Cresult). Standard SMOTE would try to interpolate categorical values, potentially creating impossible combinations like:\n",
    "- `race = 1.7` (meaningless interpolation between `\"Caucasian\"=1` and `\"African American\"=2`)\n",
    "- `medical_specialty = \"Cardiology + 0.3 * Internal Medicine\"` (nonsensical categorical interpolation)\n",
    "\n",
    "**SMOTENC Solution:**\n",
    "SMOTENC (SMOTE for Nominal and Continuous) handles mixed data types by:\n",
    "1. Continuous features: Uses standard SMOTE interpolation\n",
    "2. Categorical features: Uses the mode (most frequent value) from the k-nearest neighbors instead of interpolation\n",
    "3. Nearest neighbor calculation: Uses Gower distance metric that properly handles both data types\n",
    "\n",
    "Implementation Details:\n",
    "`categorical_features = [X.columns.get_loc(col) for col in object_features + boolean_features]`\n",
    "This tells SMOTENC which column indices contain categorical data, ensuring proper synthetic sample generation that respects the categorical nature of features like diagnosis codes and medication names.\n",
    "\n",
    "The result is realistic synthetic samples that maintain the integrity of both continuous measurements and discrete categorical classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4244e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:02:37.203456Z",
     "iopub.status.busy": "2025-07-07T14:02:37.203374Z",
     "iopub.status.idle": "2025-07-07T14:03:01.357505Z",
     "shell.execute_reply": "2025-07-07T14:03:01.357239Z"
    },
    "papermill": {
     "duration": 24.157135,
     "end_time": "2025-07-07T14:03:01.358544",
     "exception": false,
     "start_time": "2025-07-07T14:02:37.201409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (68610, 50)\n",
      "Memory usage: 0.12 GB\n",
      "CPU times: user 22.6 s, sys: 1.45 s, total: 24 s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Specify which columns are categorical (by index) \n",
    "categorical_features = [X.columns.get_loc(col) for col in object_features + boolean_features]\n",
    "\n",
    "smote_nc = SMOTENC(categorical_features=categorical_features, random_state=randy)\n",
    "X_train_resampled, y_train_resampled = smote_nc.fit_resample(X_train, y_train)\n",
    "y_train_resampled.value_counts()\n",
    "print(f\"Training data shape: {X_train_resampled.shape}\")\n",
    "print(f\"Memory usage: {X_train_resampled.memory_usage(deep=True).sum() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754da4c7",
   "metadata": {
    "papermill": {
     "duration": 0.00172,
     "end_time": "2025-07-07T14:03:01.364654",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.362934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing with ColumnTransformer\n",
    "\n",
    "This applies different transformers to different columns simultaneously:\n",
    "\n",
    "1. \"num\" step: Applies MinMaxScaler() to numeric_features\n",
    "  - Scales numeric values to range [0,1]\n",
    "2. \"cat\" step: Applies OneHotEncoder() to object_features and boolean features\n",
    "  - drop=\"first\": Removes first category to avoid multicollinearity\n",
    "  - sparse_output=True: Returns sparse matrix (memory efficient)\n",
    "  - handle_unknown=\"ignore\": Creates all-zero row for unseen categories\n",
    "\n",
    "The output combines both transformations into a single feature matrix - scaled numerics + one-hot encoded categoricals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bf5871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:03:01.368802Z",
     "iopub.status.busy": "2025-07-07T14:03:01.368707Z",
     "iopub.status.idle": "2025-07-07T14:03:01.370558Z",
     "shell.execute_reply": "2025-07-07T14:03:01.370339Z"
    },
    "papermill": {
     "duration": 0.0048,
     "end_time": "2025-07-07T14:03:01.371131",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.366331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", MinMaxScaler(), numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(drop=\"first\", sparse_output=True, handle_unknown=\"ignore\"),\n",
    "            object_features + boolean_features,\n",
    "        ),  # Combine both categorical types\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2b599b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:03:01.375298Z",
     "iopub.status.busy": "2025-07-07T14:03:01.375219Z",
     "iopub.status.idle": "2025-07-07T14:03:01.404375Z",
     "shell.execute_reply": "2025-07-07T14:03:01.404149Z"
    },
    "papermill": {
     "duration": 0.031973,
     "end_time": "2025-07-07T14:03:01.404996",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.373023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for NaNs in categorical columns...\n",
      "No NaNs found in categorical columns - safe to train!\n"
     ]
    }
   ],
   "source": [
    "# Final check of NaN's before training\n",
    "print(\"Checking for NaNs in categorical columns...\")\n",
    "categorical_cols = object_features + boolean_features\n",
    "nan_check = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    nan_count = X[col].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        nan_check[col] = nan_count\n",
    "\n",
    "if nan_check:\n",
    "    print(\"STOP! Still have NaNs:\")\n",
    "    for col, count in nan_check.items():\n",
    "        print(f\"  {col}: {count} NaNs\")\n",
    "    print(\"\\nFill these before training!\")\n",
    "else:\n",
    "    print(\"No NaNs found in categorical columns - safe to train!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c8b75",
   "metadata": {
    "papermill": {
     "duration": 0.001918,
     "end_time": "2025-07-07T14:03:01.408874",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.406956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lasso implementation\n",
    "\n",
    "We'll start with a Lasso approach first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3911eb18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:03:01.412818Z",
     "iopub.status.busy": "2025-07-07T14:03:01.412739Z",
     "iopub.status.idle": "2025-07-07T14:03:01.667815Z",
     "shell.execute_reply": "2025-07-07T14:03:01.667602Z"
    },
    "papermill": {
     "duration": 0.257651,
     "end_time": "2025-07-07T14:03:01.668454",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.410803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocessing: (68610, 2871)\n",
      "Feature expansion: 2871 features (from 50)\n",
      "Sparsity: 0.987\n"
     ]
    }
   ],
   "source": [
    "# Check feature expansion after preprocessing - in the modeling call, this is done by the pipeline function\n",
    "X_processed = preprocessor.fit_transform(X_train_resampled)\n",
    "print(f\"After preprocessing: {X_processed.shape}\")\n",
    "print(f\"Feature expansion: {X_processed.shape[1]} features (from {X_train_resampled.shape[1]})\")\n",
    "print(f\"Sparsity: {1 - X_processed.nnz / (X_processed.shape[0] * X_processed.shape[1]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b264f9",
   "metadata": {
    "papermill": {
     "duration": 0.002042,
     "end_time": "2025-07-07T14:03:01.672479",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.670437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Lasso (L1) Hyperparameter Tuning Strategy\n",
    "\n",
    "Hyperparameter Being Tuned:\n",
    "- `C`: Inverse regularization strength (0.05-1.0, log scale) - smaller values mean stronger regularization\n",
    "\n",
    "Solver Choice - LibLinear:\n",
    "LibLinear is specifically chosen for L1 regularization because:\n",
    "- Coordinate descent optimization: Efficiently handles the non-differentiable L1 penalty at zero\n",
    "- Sparse solution handling: Optimized for problems where many coefficients become exactly zero\n",
    "- Computational efficiency: Faster convergence for high-dimensional sparse problems like ours (2,871 features)\n",
    "- L1 specialization: Unlike general-purpose solvers, liblinear is designed specifically for L1-penalized problems\n",
    "\n",
    "The L1 penalty drives coefficients to exactly zero, performing automatic feature selection - critical for interpretability with our 2,871 features after one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4a57628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:03:01.676404Z",
     "iopub.status.busy": "2025-07-07T14:03:01.676303Z",
     "iopub.status.idle": "2025-07-07T14:20:35.022299Z",
     "shell.execute_reply": "2025-07-07T14:20:35.022011Z"
    },
    "papermill": {
     "duration": 1053.348856,
     "end_time": "2025-07-07T14:20:35.023102",
     "exception": false,
     "start_time": "2025-07-07T14:03:01.674246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 09:03:01,677] A new study created in memory with name: no-name-76c545af-0d21-4185-83e5-c9424a16ae54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 17, 18, 23, 24, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3, 4, 5, 23, 24, 25, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-07-07 09:20:35,019] Trial 14 finished with value: 0.7365113967633599 and parameters: {'C': 0.264729366398427}. Best is trial 11 with value: 0.7365989452921752.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 1.13 s, total: 4.03 s\n",
      "Wall time: 17min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Optuna implementation \n",
    "\n",
    "def objective(trial):\n",
    "      C = trial.suggest_float('C', .05, 1, log=True)\n",
    "\n",
    "      model = Pipeline([\n",
    "          ('preprocessor', preprocessor),\n",
    "          ('model', LogisticRegression(penalty='l1', \n",
    "                                       solver='liblinear', \n",
    "                                       C=C, \n",
    "                                       random_state=randy))\n",
    "      ])\n",
    "\n",
    "      scores = cross_val_score(model, \n",
    "                               X_train_resampled, \n",
    "                               y_train_resampled, \n",
    "                               cv=5, \n",
    "                               scoring='roc_auc',\n",
    "                               n_jobs=-1)\n",
    "      return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, \n",
    "               n_trials=100,\n",
    "               callbacks=[optuna.study.MaxTrialsCallback(n_trials=15, \n",
    "               states=[optuna.trial.TrialState.COMPLETE])])  # Much smarter than grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3d3d215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:20:35.031646Z",
     "iopub.status.busy": "2025-07-07T14:20:35.031531Z",
     "iopub.status.idle": "2025-07-07T14:20:35.034568Z",
     "shell.execute_reply": "2025-07-07T14:20:35.034357Z"
    },
    "papermill": {
     "duration": 0.007639,
     "end_time": "2025-07-07T14:20:35.035202",
     "exception": false,
     "start_time": "2025-07-07T14:20:35.027563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.21689040246062266}\n",
      "Best AUC: 0.7366\n"
     ]
    }
   ],
   "source": [
    "# After study.optimize() completes\n",
    "best_params = study.best_params\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best AUC: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b578e3d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:20:35.042528Z",
     "iopub.status.busy": "2025-07-07T14:20:35.042421Z",
     "iopub.status.idle": "2025-07-07T14:21:54.137197Z",
     "shell.execute_reply": "2025-07-07T14:21:54.136968Z"
    },
    "papermill": {
     "duration": 79.102412,
     "end_time": "2025-07-07T14:21:54.140817",
     "exception": false,
     "start_time": "2025-07-07T14:20:35.038405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as f11_log_Lasso.pkl\n",
      "CPU times: user 1min 18s, sys: 597 ms, total: 1min 19s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "log_Lasso = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                                  ('model', LogisticRegression(penalty='l1',\n",
    "                                                                 solver='liblinear',\n",
    "                                                                 C=best_params['C'],\n",
    "                                                                 random_state=randy,\n",
    "                                                                 max_iter=100000,\n",
    "                                                                 n_jobs=-1))\n",
    "                                 ])\n",
    "log_Lasso.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Save the trained model\n",
    "with open(f\"../models/{token}_log_Lasso.pkl\", \"wb\") as file:\n",
    "    pickle.dump(log_Lasso, file)\n",
    "print(f\"Model saved as {token}_log_Lasso.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59884422",
   "metadata": {
    "papermill": {
     "duration": 0.003095,
     "end_time": "2025-07-07T14:21:54.147138",
     "exception": false,
     "start_time": "2025-07-07T14:21:54.144043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Final Lasso Pipeline and Evaluation\n",
    "\n",
    "**Pipeline Components:**\n",
    "This final pipeline combines preprocessing and the optimized Lasso model:\n",
    "1. **Preprocessing**: MinMax scaling + one-hot encoding (50 → 2,871 features)\n",
    "2. **Lasso Model**: L1 regularization with optimized C parameter for automatic feature selection\n",
    "\n",
    "**Model Persistence:**\n",
    "The complete pipeline is saved as `{token}_log_Lasso.pkl`, preserving both the fitted preprocessor and trained model for deployment.\n",
    "\n",
    "**Standardized Evaluation:**\n",
    "The `evaluate_and_save_pipeline` is used here for standardized evaluation in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "225f2a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:21:54.154318Z",
     "iopub.status.busy": "2025-07-07T14:21:54.154193Z",
     "iopub.status.idle": "2025-07-07T14:21:54.155787Z",
     "shell.execute_reply": "2025-07-07T14:21:54.155603Z"
    },
    "papermill": {
     "duration": 0.006236,
     "end_time": "2025-07-07T14:21:54.156406",
     "exception": false,
     "start_time": "2025-07-07T14:21:54.150170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open a trained model\n",
    "# log_Lasso = pd.read_pickle(\"../models/f01_log_Lasso.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3770bfcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:21:54.163419Z",
     "iopub.status.busy": "2025-07-07T14:21:54.163281Z",
     "iopub.status.idle": "2025-07-07T14:21:54.960814Z",
     "shell.execute_reply": "2025-07-07T14:21:54.960584Z"
    },
    "papermill": {
     "duration": 0.801793,
     "end_time": "2025-07-07T14:21:54.961471",
     "exception": false,
     "start_time": "2025-07-07T14:21:54.159678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_version': 'f11_log_Lasso',\n",
       " 'accuracy': 0.624064881493393,\n",
       " 'precision': 0.52331897359056,\n",
       " 'recall': 0.4966228226093139,\n",
       " 'f1_score': 0.5096215230278158,\n",
       " 'specificity': np.float64(0.7066958626253314),\n",
       " 'roc_auc': np.float64(0.6529259331653884),\n",
       " 'y_test': array([0, 0, 0, ..., 1, 0, 0], dtype=int8),\n",
       " 'y_train_pred': array([1, 1, 1, ..., 1, 1, 1], dtype=int8),\n",
       " 'y_test_pred': array([0, 0, 0, ..., 1, 1, 0], dtype=int8),\n",
       " 'y_test_pred_proba': array([0.49744732, 0.21709086, 0.41688131, ..., 0.6531187 , 0.57877947,\n",
       "        0.34670747]),\n",
       " 'display_labels': array([0, 1], dtype=int8),\n",
       " 'confusion_matrix': {'tn': np.int64(6132),\n",
       "  'fp': np.int64(2545),\n",
       "  'fn': np.int64(2832),\n",
       "  'tp': np.int64(2794)},\n",
       " 'roc_curve': {'fpr': array([0.00000000e+00, 1.15247205e-04, 1.15247205e-04, ...,\n",
       "         9.94237640e-01, 9.94237640e-01, 1.00000000e+00]),\n",
       "  'tpr': array([0.00000000e+00, 0.00000000e+00, 1.77746178e-04, ...,\n",
       "         9.99822254e-01, 1.00000000e+00, 1.00000000e+00]),\n",
       "  'thresholds': array([       inf, 0.95096675, 0.94429994, ..., 0.01364071, 0.01351902,\n",
       "         0.00340916])},\n",
       " 'shap_data': {'model': Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num', MinMaxScaler(),\n",
       "                                                    ['age', 'admission_type_id',\n",
       "                                                     'discharge_disposition_id',\n",
       "                                                     'admission_source_id',\n",
       "                                                     'time_in_hospital',\n",
       "                                                     'num_lab_procedures',\n",
       "                                                     'num_procedures',\n",
       "                                                     'num_medications',\n",
       "                                                     'number_outpatient',\n",
       "                                                     'number_emergency',\n",
       "                                                     'number_inpatient',\n",
       "                                                     'number_diagnoses', 'change',\n",
       "                                                     'diabetesMed', 'A1C_tested',...\n",
       "                                                     'medical_subspecialty',\n",
       "                                                     'discharge_disposition_group',\n",
       "                                                     'admission_source_group',\n",
       "                                                     'age_group', 'primary_group',\n",
       "                                                     'primary_subgroup',\n",
       "                                                     'secondary_group',\n",
       "                                                     'secondary_subgroup',\n",
       "                                                     'secondary2_group',\n",
       "                                                     'secondary2_subgroup',\n",
       "                                                     'change', 'diabetesMed', ...])])),\n",
       "                  ('model',\n",
       "                   LogisticRegression(C=0.21689040246062266, max_iter=100000,\n",
       "                                      n_jobs=-1, penalty='l1', random_state=42,\n",
       "                                      solver='liblinear'))]),\n",
       "  'X_train_processed': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "  \twith 2621451 stored elements and shape (68610, 2871)>,\n",
       "  'X_test_processed': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "  \twith 545312 stored elements and shape (14303, 2871)>,\n",
       "  'feature_names': array(['num__age', 'num__admission_type_id',\n",
       "         'num__discharge_disposition_id', ..., 'cat__diabetesMed_True',\n",
       "         'cat__A1C_tested_True', 'cat__substitution_True'], dtype=object),\n",
       "  'original_feature_names': ['encounter_id',\n",
       "   'patient_nbr',\n",
       "   'race',\n",
       "   'gender',\n",
       "   'age',\n",
       "   'admission_type_id',\n",
       "   'discharge_disposition_id',\n",
       "   'admission_source_id',\n",
       "   'time_in_hospital',\n",
       "   'medical_specialty',\n",
       "   'num_lab_procedures',\n",
       "   'num_procedures',\n",
       "   'num_medications',\n",
       "   'number_outpatient',\n",
       "   'number_emergency',\n",
       "   'number_inpatient',\n",
       "   'diag_1',\n",
       "   'diag_2',\n",
       "   'diag_3',\n",
       "   'number_diagnoses',\n",
       "   'max_glu_serum',\n",
       "   'A1Cresult',\n",
       "   'metformin',\n",
       "   'chlorpropamide',\n",
       "   'glimepiride',\n",
       "   'glipizide',\n",
       "   'glyburide',\n",
       "   'pioglitazone',\n",
       "   'rosiglitazone',\n",
       "   'tolazamide',\n",
       "   'insulin',\n",
       "   'glyburide-metformin',\n",
       "   'change',\n",
       "   'diabetesMed',\n",
       "   'medical_subspecialty',\n",
       "   'discharge_disposition_group',\n",
       "   'admission_source_group',\n",
       "   'A1C_tested',\n",
       "   'service_utilization',\n",
       "   'substitution',\n",
       "   'med_change_count',\n",
       "   'diabetes_meds_used',\n",
       "   'num_nondiabetic_medications',\n",
       "   'age_group',\n",
       "   'primary_group',\n",
       "   'primary_subgroup',\n",
       "   'secondary_group',\n",
       "   'secondary_subgroup',\n",
       "   'secondary2_group',\n",
       "   'secondary2_subgroup']}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_save_pipeline(\n",
    "    pipeline=log_Lasso, \n",
    "    namestring='log_Lasso',\n",
    "    token=token, \n",
    "    X_train=X_train_resampled, \n",
    "    X_test=X_test, \n",
    "    y_train=y_train_resampled, \n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06348366",
   "metadata": {
    "papermill": {
     "duration": 0.003552,
     "end_time": "2025-07-07T14:21:54.968443",
     "exception": false,
     "start_time": "2025-07-07T14:21:54.964891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Elasticnet implementation\n",
    "\n",
    "### Elastic Net Hyperparameter Tuning Strategy\n",
    "\n",
    "Hyperparameters Being Tuned:\n",
    "- `C`: Inverse regularization strength (0.01-0.5, log scale) - controls overall penalty magnitude\n",
    "- `l1_ratio`: Mixing parameter (0.1-0.9) - balances L1 vs L2 regularization (0=Ridge, 1=Lasso)\n",
    "\n",
    "Solver Choice - SAGA:\n",
    "SAGA is required for Elastic Net because:\n",
    "- Dual penalty support: Only solver in scikit-learn that handles both L1 and L2 penalties simultaneously\n",
    "- Stochastic optimization: Uses variance-reduced stochastic gradients for efficient convergence on large datasets\n",
    "- Numerical stability: Better handles the combined L1+L2 penalty term without convergence issues\n",
    "- Flexibility: Can handle the full spectrum from pure Ridge (`l1_ratio=0`) to pure Lasso (`l1_ratio=1`)\n",
    "\n",
    "Elastic Net combines L1's feature selection with L2's coefficient shrinkage, potentially providing better performance when groups of correlated\n",
    "features exist (common in our medical dataset with related diagnostic codes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24de2955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T14:21:54.976105Z",
     "iopub.status.busy": "2025-07-07T14:21:54.975997Z",
     "iopub.status.idle": "2025-07-07T15:22:16.692282Z",
     "shell.execute_reply": "2025-07-07T15:22:16.691998Z"
    },
    "papermill": {
     "duration": 3621.72452,
     "end_time": "2025-07-07T15:22:16.696873",
     "exception": false,
     "start_time": "2025-07-07T14:21:54.972353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 09:21:54,977] A new study created in memory with name: no-name-05cb662a-1b0c-4946-894a-247eb589e298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [3, 4, 5, 23, 24, 25, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "[I 2025-07-07 10:22:16,689] Trial 7 finished with value: 0.7374019266666993 and parameters: {'C': 0.14720803388280645, 'l1_ratio': 0.3640218127141768}. Best is trial 7 with value: 0.7374019266666993.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.55 s, sys: 1.88 s, total: 5.43 s\n",
      "Wall time: 1h 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def objective_enet(trial):\n",
    "    C = trial.suggest_float('C', 0.01, 0.5, log=True)  # Narrower range based on your CV result\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0.1, 0.9)  # ElasticNet mixing parameter\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(\n",
    "            penalty='elasticnet',\n",
    "            solver='saga',  # Only solver that supports elasticnet\n",
    "            C=C,\n",
    "            l1_ratio=l1_ratio,  # New parameter for ElasticNet\n",
    "            random_state=randy,\n",
    "            max_iter=100000\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train_resampled,\n",
    "        y_train_resampled,\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1  # Keep for CV parallelization\n",
    "    )\n",
    "    return scores.mean()\n",
    "\n",
    "study_enet = optuna.create_study(direction='maximize')\n",
    "study_enet.optimize(\n",
    "    objective_enet,\n",
    "    n_trials=50,  # Fewer trials to speed up\n",
    "    timeout=3600  # Stop after 1 hour max\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3006c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:22:16.707976Z",
     "iopub.status.busy": "2025-07-07T15:22:16.707849Z",
     "iopub.status.idle": "2025-07-07T15:22:16.710481Z",
     "shell.execute_reply": "2025-07-07T15:22:16.710267Z"
    },
    "papermill": {
     "duration": 0.008531,
     "end_time": "2025-07-07T15:22:16.711086",
     "exception": false,
     "start_time": "2025-07-07T15:22:16.702555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ElasticNet params: {'C': 0.14720803388280645, 'l1_ratio': 0.3640218127141768}\n",
      "Best ElasticNet AUC: 0.7374\n"
     ]
    }
   ],
   "source": [
    "# After study.optimize() completes\n",
    "best_params = study_enet.best_params\n",
    "print(f\"Best ElasticNet params: {study_enet.best_params}\")\n",
    "print(f\"Best ElasticNet AUC: {study_enet.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f87329cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:22:16.719507Z",
     "iopub.status.busy": "2025-07-07T15:22:16.719428Z",
     "iopub.status.idle": "2025-07-07T15:27:49.615869Z",
     "shell.execute_reply": "2025-07-07T15:27:49.615625Z"
    },
    "papermill": {
     "duration": 332.904796,
     "end_time": "2025-07-07T15:27:49.619956",
     "exception": false,
     "start_time": "2025-07-07T15:22:16.715160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as f11_log_ENet.pkl\n",
      "CPU times: user 5min 32s, sys: 151 ms, total: 5min 32s\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "log_ENet = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                                  ('model', LogisticRegression(penalty='elasticnet',\n",
    "                                                                 solver='saga',\n",
    "                                                                 C=best_params['C'],\n",
    "                                                                 l1_ratio=best_params['l1_ratio'],\n",
    "                                                                 random_state=randy,\n",
    "                                                                 max_iter=100000,\n",
    "                                                                 n_jobs=-1 ))\n",
    "                                 ])\n",
    "log_ENet.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Save the trained model\n",
    "with open(f\"../models/{token}_log_ENet.pkl\", \"wb\") as file:\n",
    "    pickle.dump(log_ENet, file)\n",
    "print(f\"Model saved as {token}_log_ENet.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a873a",
   "metadata": {
    "papermill": {
     "duration": 0.003955,
     "end_time": "2025-07-07T15:27:49.628026",
     "exception": false,
     "start_time": "2025-07-07T15:27:49.624071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Final Elastic Net Pipeline and Evaluation\n",
    "\n",
    "**Pipeline Components:**\n",
    "This final pipeline combines preprocessing and the optimized Elastic Net model:\n",
    "1. Preprocessing: MinMax scaling + one-hot encoding (50 → 2,871 features)\n",
    "2. Elastic Net Model: Combined L1+L2 regularization with optimized C and l1_ratio parameters\n",
    "\n",
    "**Model Persistence:**\n",
    "The complete pipeline is saved as `{token}_log_ENet.pkl`, preserving both the fitted preprocessor and trained model for deployment.\n",
    "\n",
    "**Standardized Evaluation:**\n",
    "The same `evaluate_and_save_pipeline()` function is used here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8cd84b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:49.636868Z",
     "iopub.status.busy": "2025-07-07T15:27:49.636766Z",
     "iopub.status.idle": "2025-07-07T15:27:49.638294Z",
     "shell.execute_reply": "2025-07-07T15:27:49.638088Z"
    },
    "papermill": {
     "duration": 0.006765,
     "end_time": "2025-07-07T15:27:49.638848",
     "exception": false,
     "start_time": "2025-07-07T15:27:49.632083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open a trained model\n",
    "# log_ENet = pd.read_pickle(\"../models/f01_log_ENet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0a0f12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T15:27:49.647615Z",
     "iopub.status.busy": "2025-07-07T15:27:49.647531Z",
     "iopub.status.idle": "2025-07-07T15:27:50.436277Z",
     "shell.execute_reply": "2025-07-07T15:27:50.436083Z"
    },
    "papermill": {
     "duration": 0.79383,
     "end_time": "2025-07-07T15:27:50.436881",
     "exception": false,
     "start_time": "2025-07-07T15:27:49.643051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cwaters/diabetes/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2, 3, 4, 5, 22, 23, 25, 26, 27] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_version': 'f11_log_ENet',\n",
       " 'accuracy': 0.6234356428721247,\n",
       " 'precision': 0.5222222222222223,\n",
       " 'recall': 0.5012442232492001,\n",
       " 'f1_score': 0.511518229639035,\n",
       " 'specificity': np.float64(0.7026622104413968),\n",
       " 'roc_auc': np.float64(0.6533970414530635),\n",
       " 'y_test': array([0, 0, 0, ..., 1, 0, 0], dtype=int8),\n",
       " 'y_train_pred': array([1, 1, 1, ..., 1, 1, 1], dtype=int8),\n",
       " 'y_test_pred': array([1, 0, 0, ..., 1, 1, 0], dtype=int8),\n",
       " 'y_test_pred_proba': array([0.50322397, 0.21800525, 0.4239119 , ..., 0.6370222 , 0.55686554,\n",
       "        0.34375856]),\n",
       " 'display_labels': array([0, 1], dtype=int8),\n",
       " 'confusion_matrix': {'tn': np.int64(6097),\n",
       "  'fp': np.int64(2580),\n",
       "  'fn': np.int64(2806),\n",
       "  'tp': np.int64(2820)},\n",
       " 'roc_curve': {'fpr': array([0.00000000e+00, 1.15247205e-04, 1.15247205e-04, ...,\n",
       "         9.93430909e-01, 9.93430909e-01, 1.00000000e+00]),\n",
       "  'tpr': array([0.00000000e+00, 0.00000000e+00, 1.77746178e-04, ...,\n",
       "         9.99822254e-01, 1.00000000e+00, 1.00000000e+00]),\n",
       "  'thresholds': array([       inf, 0.94818397, 0.93990362, ..., 0.01983515, 0.01981003,\n",
       "         0.00427329])},\n",
       " 'shap_data': {'model': Pipeline(steps=[('preprocessor',\n",
       "                   ColumnTransformer(transformers=[('num', MinMaxScaler(),\n",
       "                                                    ['age', 'admission_type_id',\n",
       "                                                     'discharge_disposition_id',\n",
       "                                                     'admission_source_id',\n",
       "                                                     'time_in_hospital',\n",
       "                                                     'num_lab_procedures',\n",
       "                                                     'num_procedures',\n",
       "                                                     'num_medications',\n",
       "                                                     'number_outpatient',\n",
       "                                                     'number_emergency',\n",
       "                                                     'number_inpatient',\n",
       "                                                     'number_diagnoses', 'change',\n",
       "                                                     'diabetesMed', 'A1C_tested',...\n",
       "                                                     'discharge_disposition_group',\n",
       "                                                     'admission_source_group',\n",
       "                                                     'age_group', 'primary_group',\n",
       "                                                     'primary_subgroup',\n",
       "                                                     'secondary_group',\n",
       "                                                     'secondary_subgroup',\n",
       "                                                     'secondary2_group',\n",
       "                                                     'secondary2_subgroup',\n",
       "                                                     'change', 'diabetesMed', ...])])),\n",
       "                  ('model',\n",
       "                   LogisticRegression(C=0.14720803388280645,\n",
       "                                      l1_ratio=0.3640218127141768,\n",
       "                                      max_iter=100000, n_jobs=-1,\n",
       "                                      penalty='elasticnet', random_state=42,\n",
       "                                      solver='saga'))]),\n",
       "  'X_train_processed': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "  \twith 2621451 stored elements and shape (68610, 2871)>,\n",
       "  'X_test_processed': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "  \twith 545312 stored elements and shape (14303, 2871)>,\n",
       "  'feature_names': array(['num__age', 'num__admission_type_id',\n",
       "         'num__discharge_disposition_id', ..., 'cat__diabetesMed_True',\n",
       "         'cat__A1C_tested_True', 'cat__substitution_True'], dtype=object),\n",
       "  'original_feature_names': ['encounter_id',\n",
       "   'patient_nbr',\n",
       "   'race',\n",
       "   'gender',\n",
       "   'age',\n",
       "   'admission_type_id',\n",
       "   'discharge_disposition_id',\n",
       "   'admission_source_id',\n",
       "   'time_in_hospital',\n",
       "   'medical_specialty',\n",
       "   'num_lab_procedures',\n",
       "   'num_procedures',\n",
       "   'num_medications',\n",
       "   'number_outpatient',\n",
       "   'number_emergency',\n",
       "   'number_inpatient',\n",
       "   'diag_1',\n",
       "   'diag_2',\n",
       "   'diag_3',\n",
       "   'number_diagnoses',\n",
       "   'max_glu_serum',\n",
       "   'A1Cresult',\n",
       "   'metformin',\n",
       "   'chlorpropamide',\n",
       "   'glimepiride',\n",
       "   'glipizide',\n",
       "   'glyburide',\n",
       "   'pioglitazone',\n",
       "   'rosiglitazone',\n",
       "   'tolazamide',\n",
       "   'insulin',\n",
       "   'glyburide-metformin',\n",
       "   'change',\n",
       "   'diabetesMed',\n",
       "   'medical_subspecialty',\n",
       "   'discharge_disposition_group',\n",
       "   'admission_source_group',\n",
       "   'A1C_tested',\n",
       "   'service_utilization',\n",
       "   'substitution',\n",
       "   'med_change_count',\n",
       "   'diabetes_meds_used',\n",
       "   'num_nondiabetic_medications',\n",
       "   'age_group',\n",
       "   'primary_group',\n",
       "   'primary_subgroup',\n",
       "   'secondary_group',\n",
       "   'secondary_subgroup',\n",
       "   'secondary2_group',\n",
       "   'secondary2_subgroup']}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_and_save_pipeline(\n",
    "    pipeline=log_ENet, \n",
    "    namestring='log_ENet',\n",
    "    token=token, \n",
    "    X_train=X_train_resampled, \n",
    "    X_test=X_test, \n",
    "    y_train=y_train_resampled, \n",
    "    y_test=y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5117.818636,
   "end_time": "2025-07-07T15:27:53.060903",
   "environment_variables": {},
   "exception": null,
   "input_path": "p03_logreg.ipynb",
   "output_path": "outputs/p03_logreg_executed.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T14:02:35.242267",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}